---
title: "Working Memory"
pubDate: 2024-05-09
description: "Stack brains, queue brains, and the capacity of working memory"
categories: [cognition, psychology, essays, science]
---

*Update (06-17-24): Since writing this article, I would now update the comparison of queue and stack brains to focus on the time decay of working memory rather than its absolute capacity. That said, the original analysis in this essay -- of continuous-resource models and interference -- presents complementary theories for working memory capacity that I still find useful.*

I have a running debate with a friend about whether it’s better to be queue-brained or stack-brained. By this, what we mean is: is it better to evaluate inputs in a first-in last-out manner (queue) or a first-in first-out manner (stack)? Though I consider myself queue-brained, their stack-biased arguments are compelling: first, a stack brain lets you respond to threats quickly – for example, if you see an oncoming bus, jumping out of the way would be a great first step. Other tasks can wait. Second, stack brains can hold multiple layers of tasks at the same time, solving subproblems and subproblems of subproblems as they come up. On the other hand, stack-brained people risk leaving tasks unresolved. In a conversation, for example, a stack-brained person will build up layer upon layer of nested topics, and then go back through the topics in reverse order.  

But wait a minute – can the stack-brained person really keep building up layers of conversational topics? Or is there a limit to the brain’s capacity to store layers? A limit to the brain’s working memory capacity could represent a major downside for the stack-brained advocates – soon the brain would run out of space to represent additional conversational layers, and some topics would have to be forgotten. This is what programmers would call a stack overflow error. In contrast, a queue-brained person would have no problem evaluating any number of conversational topics in order, storing only one topic at a time.  

In an attempt to answer this question – whether there is a limit to working memory – and to settle my debate scientifically, we need to know how many “units” of working memory a person can store. This way, we can see if the number of units is sufficient for a stack brain to be practical. To do so, however, we must first consider what these fundamental units are. If we consider numbers – the simplest kind of information to reason about – then the capacity of working memory can be estimated easily. Intuitively speaking, most people can probably remember more than 1 digit but not more than 20 in their working memory. But what if people are especially good or bad at remembering numbers? Our capacity for remembering numbers alone may not reflect the universal capacity of working memory.  

One early and influential attempt at determining the number of generalized “chunks” a person can store came from psychologist George A. Miller, in a 1956 paper announcing the “magical number” seven. After reviewing the relevant research, Miller had noticed that most people can only remember about seven plus-or-minus-two things at a time (whether words, shapes, or otherwise), but they could remember more if they chunked a larger number of things into about seven units [1]. For example, a person might be able to remember a string of fourteen numbers if they remember them in chunks of two. As a refinement to Miller’s original theory, Nelson Cowan suggested in 2001 that the actual number of memory slots was around four – the “magical number” four [2].  

But such rough numbers can only get us so far. For example, if you are sitting at a desk or table, take a quick scan of the objects in front of you, and then close your eyes. Try to remember what you just saw on the table, and you might find that you remember more than 4 things. Now open your eyes, so that you can continue reading this essay. What do you mean if you say you remembered 4 objects? Did you remember the full objects themselves, or only some loose impression of those objects? For example, on my desk right now, I have a book standing upright. Facing me is a back cover filled with a number of glowing reviews (eight, to be precise). In my memory, however, the book is no more than a blank white hardcover with inscrutable text printed on the back. So I didn’t remember the text on the book, but I did remember that it was white and hardcover – how many slots does that count as?  

Because of its ill-defined nature, a discrete slots-based model may be a good heuristic for deciding how much people can remember (for example, for deciding how many steps should be placed on a hypothetical Oxford dorm’s fire escape plan). But it might not be sophisticated enough to resolve my stack-queue debate. For that, an alternative comes from resource models. As Ma and colleagues describe it, a resource model also assumes that working memory capacity is limited, but models a tradeoff between item precision and number of items – maybe people can remember more than 4 items if they store each item at a lower precision. To measure the concept of precision, they swap out a discrete response task – like “remember these 5 letters” – for a continuous response task – like “remember this color” – in an experimental paradigm called a delayed estimation task. In this delayed estimation task, the difference between the remembered color and the actual color falls along a continuous spectrum, allowing the researchers to graph the remembered precision. As the resource model would predict, the standard deviation of remembered colors rises as the number of items to remember increases, implying decreased precision as the number of objects increases.  

Almost all the visual capacity studies mentioned so far concern simple stimuli like digits and colors, but the results may not generalize to real-world objects. Brady and colleagues showed that working memory could be more flexible than originally thought when it comes to real-world objects [4]. They tested participants’ memories for real-world objects as well as stimuli like shapes and colors, presented for either 200, 1000, or 2000 milliseconds (about 2 seconds). At the 200 millisecond mark, both objects and colors were remembered up to about 3 items. In the 1 second trials, the two cases diverged – while the number of remembered colors did not increase significantly, the number of remembered objects jumped to an average of over four. In the 2 second trials, the number of remembered objects increased a bit more. If we take this study seriously, then all the previous studies of slots-based models focused on words, shapes, or colors, may underestimate the flexibility – or as an economist might say, elasticity – of working memory capacity in real-world environments.  

At this point, defenders of the slots-based model might be tempted to jump in and protest: “Wait a minute! Your working memory in general may be larger, but the magical number of slots may refer to the part of working memory that you can attend to at any given time.” To address this more nuanced counterpoint, we could start by answering why the brain must have a working memory capacity limit at all. Why does working memory seem so restrictive? A naive answer would be decay: if working memory requires neurons to consistently fire in a particular pattern, this firing pattern might weaken over time, due to a lack of sufficient energy or information loss in the network. Without any outside inputs, memories would simply decay over time.  

An alternative reason that working memory is limited is interference from other stimuli. As Timoth Buschman explains in a 2021 review, interference occurs when multiple items in memory need to use the same cognitive resources. According to Buschman, interference takes two forms: first, there is representational interference, in which two items co-opt similar representations in memory – for example, two locations that are close together in space might be encoded by many of the same neurons in a similar way, making them difficult to distinguish in memory. The second type of interference is competitive interference, in which the items’ representations may be uncorrelated but they use the same neurons regardless – here, limits to the total neural network activity can explain a limit to the number of representable items [5].  

In contrast to the decay hypothesis, which has limited behavioral evidence,  the interference hypothesis aligns well with results from EEG and fMRI. According to a paper by Manohar and colleagues in 2019, these imaging studies seem to show that posterior brain areas contain representational maps (feature neurons), whereas the frontal cortex contains general-purpose neurons that flexibly represent the focus of attention in working memory. As a mechanism for maintaining working memory, the actively attended feature neurons and frontal neurons persistently fire, whereas the non-attended feature neurons retain a temporary synaptic weight adjustment corresponding to the working-memory frontal neurons [6]. Though more neuron-level studies are needed to verify its accuracy, this interference model aligns well with the biased competition theory of attention – feature neurons compete to send signals to frontal neurons, and their outgoing signals are biased by the subject of attention in working memory.  

Even having discussed continuous-resource models of working memory and interference explanations of working memory capacity limits, we are left with many questions: first, how do these results generalize to cases of non-visual working memory? It’s possible that semantic working memory – the working memory of concepts – differs in its capacity from visual working memory, as Brady and colleagues suggested in their study of real-world objects. Second, how is working memory affected by context and prior knowledge? Most studies avoid these factors, despite their importance in real-world situations. And most importantly, where do all these theories leave us with our original debate: is it better to be stack brained or queue brained?  

The answer, rather boringly, is that it depends on the situation. With tasks prone to interference or demanding high precision memory, a queue brain may be preferable. This might be true of things like writing proofs or programming, in which pen and paper can be used to remember the task context. For tasks of a nested nature, such as conversation, the stack brain may be more effective, because it allows speakers to traverse nested topics without an external memory store. In reality, all of these tasks probably involve a combination of the two approaches to thinking, as well as non-linear random-access approaches and efficient encoding mechanisms.  

Perhaps stack brains and queue brains are all inefficient – someone truly interested in optimized conversation might prefer something like a priority queue, with items ordered based on recent access. They should also encode each previous conversation topic with a letter, like “topic A, B, C,” and so on, for space-efficient retrieval, and link topic symbols using pointers based on their interrelationships. By this time, they would also notice that their conversation partner had run off to talk to someone more interesting.  

 

References 

[1] Miller, G. A. (1956). The magical number seven, plus or minus two: Some limits on our capacity for processing information. Psychological Review, 63(2), 81–97. https://doi.org/10.1037/h0043158 

[2] Cowan N. (2001). The magical number 4 in short-term memory: a reconsideration of mental storage capacity. The Behavioral and brain sciences, 24(1), 87–185. https://doi.org/10.1017/s0140525x01003922 

[3] Ma, W. J., Husain, M., & Bays, P. M. (2014). Changing concepts of working memory. Nature neuroscience, 17(3), 347–356. https://doi.org/10.1038/nn.3655 

[4] Brady, T. F., Störmer, V. S., & Alvarez, G. A. (2016). Working memory is not fixed-capacity: More active storage capacity for real-world objects than for simple stimuli. Proceedings of the National Academy of Sciences of the United States of America, 113(27), 7459–7464. https://doi.org/10.1073/pnas.1520027113 

[5] Buschman T. J. (2021). Balancing Flexibility and Interference in Working Memory. Annual review of vision science, 7, 367–388. https://doi.org/10.1146/annurev-vision-100419-104831 

[6] Manohar, S. G., Zokaei, N., Fallon, S. J., Vogels, T. P., & Husain, M. (2019). Neural mechanisms of attending to items in working memory. Neuroscience and biobehavioral reviews, 101, 1–12. https://doi.org/10.1016/j.neubiorev.2019.03.017 