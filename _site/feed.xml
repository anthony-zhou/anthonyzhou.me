<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Anthony Zhou</title>
    <description>Psychology, Economics, Programming, or anything interesting. Updated Weekly.</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Wed, 12 Feb 2020 17:36:39 -0600</pubDate>
    <lastBuildDate>Wed, 12 Feb 2020 17:36:39 -0600</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Can we achieve symbiosis with machines? Neuralink and Facebook try to answer the question.</title>
        <description>&lt;p&gt;Today’s internet-enabled devices are competing for our attention, all the time. What if there was some way we could escape the loop of digital addiction? What if we could become one with our machines?&lt;/p&gt;

&lt;p&gt;Enter the Brain-Machine Interface (BMI), also known as a brain-computer interface (BCI), mind-machine interface (MMI), or direct neural interface (DNI): a device that translates neural signals into commands that control hardware or software.&lt;/p&gt;

&lt;p&gt;The premise is simple. Currently, we interface with technology, and the outside world in general, through low-bandwidth options like keyboards and speech. For argument’s sake, assume that your words-per-minute (WPM) when speaking is 150 (about average, according to the National Center for Voice and Speech), and that your WPM when typing is 75 (you can get a rough estimate of your typing speed with &lt;a href=&quot;https://thetypingcat.com/typing-speed-test/1m&quot;&gt;this minute-long test&lt;/a&gt;). Compare that with your brain, a highly efficient computer that may have as many as 50 processes running at the same time, as noted in this article from &lt;a href=&quot;https://www.technologyreview.com/s/532291/fmri-data-reveals-the-number-of-parallel-processes-running-in-the-brain/&quot;&gt;the MIT Technology Review&lt;/a&gt;. Each one of us has a brain full of countless ideas and connections that never make it out into the real world, due simply to the ridiculously slow rate of communication between our powerful brains and the outside world.&lt;/p&gt;

&lt;p&gt;Think about how much time the average American spends on any kind of technology. &lt;a href=&quot;https://www.inc.com/melanie-curtin/are-you-on-your-phone-too-much-average-person-spends-this-many-hours-on-it-every-day.html&quot;&gt;According to Inc magazine&lt;/a&gt;, the answer is &lt;em&gt;over four hours&lt;/em&gt;. Our society is just beginning to realize the way digital overload can isolate us from nature and the people closest to us, but becoming a hermit and moving to a cabin in the woods doesn’t seem so feasible. Is there any way we could use technology to enhance our lives rather than distracting from them? This is the vision Facebook Reality Labs has for its Brain-Computer Interface:&lt;/p&gt;

&lt;h2 id=&quot;facebook-reality-labs&quot;&gt;Facebook Reality Labs&lt;/h2&gt;

&lt;blockquote&gt;
  &lt;p&gt;Imagine a world where all the knowledge, fun, and utility of today’s smartphones were instantly accessible and completely hands-free. Where you could spend quality time with the people who matter most in your life, whenever you want, no matter where in the world you happen to be. And where you could connect with others in a meaningful way, regardless of external distractions, geographic constraints, and even physical disabilities and limitations.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;In July of 2019, Facebook Reality Labs released &lt;a href=&quot;https://tech.fb.com/imagining-a-new-interface-hands-free-communication-without-saying-a-word/&quot;&gt;this report&lt;/a&gt; detailing some cutting edge work with the BCI. The lab sponsored a group of University of California, San Francisco (UCSF) researchers who are working to help patients with neurological diseases like ALS use brain-computer interfaces to communicate. BCI technology, as the report notes, is not new: it already helps people “feed themselves, hold the hand of a loved one, and even fly a jet simulator.” So why don’t we all have computers in our brains? There are two limiting factors in BCI development: speed and invasiveness.&lt;/p&gt;

&lt;h3 id=&quot;talking-fast-and-talking-slow-balancing-speed-and-invasiveness-in-bmis&quot;&gt;Talking fast and talking slow: balancing speed and invasiveness in BMIs&lt;/h3&gt;

&lt;p&gt;Emily Mugler, an engineer on the Facebook Reality Labs BCI team, describes how the conventional approach of electroencephalography (EEG), where a cap of electrodes is placed on the subjects head, was just not fast enough for patients with ALS to communicate their ideas effectively. “It sometimes took 70 minutes for a patient to type a single sentence,” she says.&lt;/p&gt;

&lt;p&gt;Later, some labs attempted using electrocorticography (ECoG), which was faster but required a surgical operation inserting electrodes into the brain. Herein lies the problem that plagued past attempt to develop an effective BCI: fast technologies tend to be too invasive, whereas noninvasive solutions tend to be too slow. Researchers found themselves perplexed with the problem of getting inside the brain without physically getting inside the brain.&lt;/p&gt;

&lt;p&gt;Facebook Reality Labs, together with the lab at UCSF, plans to solve this problem with near-infrared light: by beaming harmless light waves into the subject’s brain, a wearable device can sense blood oxygenation—much like in an fMRI (functional magnetic resonance imaging) machine—and use the measurements to guess at brain activity. While the system is currently “bulky, slow, and unreliable,” the UCSF researchers have successfully converted thoughts to words in real time and hope to reach a speed of 100 words per minute on a 1000 word vocabulary with an error of less than 17% (&lt;a href=&quot;https://www.nature.com/articles/s41467-019-10994-4&quot;&gt;Read more in their &lt;em&gt;Nature Communications&lt;/em&gt; journal article&lt;/a&gt;).&lt;/p&gt;

&lt;p&gt;The results are promising. Perhaps within a decade we will see keyboards by and large replaced by brain-machine interfaces, bringing us into a world where we could spend our lives connecting with others in a meaningful way, enabled by rather than encumbered by technology. But the universal adoption of BCIs raises serious issues of privacy. Can privacy even exist when our inner thoughts are exposed to the public? Moreover, Facebook is not the company many would most trust to safeguard their personal information, given its recent scandals.&lt;/p&gt;

&lt;p&gt;Fear not, for Facebook is not the only one developing this technology: Elon Musk has founded a company developing the Neuralink, a brain-machine interface with no qualms about physically invading your brain.&lt;/p&gt;

&lt;h2 id=&quot;neuralink---elon-musk&quot;&gt;Neuralink - Elon Musk&lt;/h2&gt;

&lt;p&gt;Elon Musk’s justification for the need for a brain-machine interface goes something like this:&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;You could sort of think of humanity as a biological bootloader for digital superintelligence&lt;/p&gt;
  &lt;ul&gt;
    &lt;li&gt;Elon Musk&lt;/li&gt;
  &lt;/ul&gt;
&lt;/blockquote&gt;

&lt;p&gt;Here, “bootloader” refers to the small piece of code needed to start up a computer. To explain this idea further, let’s examine the recent trends in artificial intelligence, as viewed in a Muskian mindset:&lt;/p&gt;

&lt;p&gt;AI is set to overtake humanity as the next stage in the evolution of consciousness. We’ll have gone from amoebas to lizards to chimps to humans to machines. Or something like that. Scary, right? While the truth of Musk’s statement is debatable, the underlying trend rings true: artificial intelligence, and technology in general, is expanding to replace many traditionally human tasks, from manufacturing to truck driving to being a cashier at McDonald’s. How can we escape the ultimate supremacy of AI?&lt;/p&gt;

&lt;p&gt;The answer is that we integrate the machines into ourselves, so that we can work together with our revolutionary technology rather than competing against it. A brain-machine interface would help us both drastically increase our productivity and avoid becoming obsolete. If you subscribe to Musk’s view of the inevitable march of technology (detailed in &lt;a href=&quot;https://www.youtube.com/watch?v=f3lUEnMaiAU&quot;&gt;this interview&lt;/a&gt;), we have two options: brain-machine interface or extinction as AI takes over.&lt;/p&gt;

&lt;p&gt;How does the Neuralink work? By inserting tiny electrodes linked to wires with diameter of 4-6 microns, or less than a quarter of the thickness of a typical human hair. The procedure goes like this: drill a 2 mm hole in the subject’s brain, then use a “sewing machine” to weave up to 96 tiny threads into the brain, creating 3,072 channels. As with all things Elon, Musk plans to push the Neuralink forward at a rapid pace, starting human clinical trials by the end of 2020, focusing on brain diseases, and envisioning widespread adoption in 4 to 5 years.&lt;/p&gt;

&lt;p&gt;It sounds scary because it is. With apparently little regard to the potential brain damage incurred by invasive surgery, the Neuralink in its current state creates two major health risks: glial scarring and broken electrodes. Glial scarring refers to scarring in the brain tissue that can inhibit communication and represents a reaction to serious brain damage. Meanwhile, the small electrodes used by the Neuralink are impossible to extract if broken, meaning they’ll just be stuck in the patient’s brain.&lt;/p&gt;

&lt;p&gt;Musk offers a compelling vision of the future—one in which we have achieved a “symbiosis with machines”—but the Neuralink’s radical approach to and bold vision for the BMI may end up rushing to offer the world a half-cooked dish that leaves us a little sick to the stomach. Whether or not the technical and health-related challenges are resolved, the Muskian view would tell us that the need to stay relevant in a world of increasing automation outweighs the health risks incurred.&lt;/p&gt;

&lt;h2 id=&quot;what-happens-next&quot;&gt;What happens next&lt;/h2&gt;

&lt;p&gt;As with any technology, the brain-machine interface has great benefits and drawbacks that will affect people unequally, although both the utopian and dystopian views are probably overstated. In the end, many of our fears will probably be nullified as the technology improves and as a lack of privacy becomes the new normal. After all, the subjective truths of today, like privacy, may not hold steady even ten years into the future.&lt;/p&gt;

&lt;p&gt;And China’s going to do it anyway.&lt;/p&gt;

&lt;p&gt;No matter what, it remains essential that the public holds Facebook, Neuralink, and the smorgasbord of BMI startups accountable, to ensure we don’t rush blindly into a technology without asking ourselves whether it truly makes the world a better place.&lt;/p&gt;

&lt;h3 id=&quot;further-reading-and-works-cited&quot;&gt;Further reading and works cited&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;An article on the Neuralink: https://venturebeat.com/2019/07/16/neuralinks-technology-embeds-tiny-wires-in-the-brain-to-read-electrical-pulses/&lt;/li&gt;
  &lt;li&gt;The Neuralink plans to start clinical trials by the end of 2020: https://www.cnbc.com/2019/07/17/elon-musk-brain-machine-startup-neuralink-plans-human-trials-in-2020.html&lt;/li&gt;
  &lt;li&gt;The Wikipedia article talking about glial scarring and broken electrodes: https://en.wikipedia.org/wiki/Neuralink&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Mon, 03 Feb 2020 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/brain-machine-interface/</link>
        <guid isPermaLink="true">http://localhost:4000/brain-machine-interface/</guid>
        
        <category>neuroscience</category>
        
        <category>artificial intelligence</category>
        
        
        <category>psychology</category>
        
        <category>essays</category>
        
        <category>science</category>
        
      </item>
    
      <item>
        <title>The Many Definitions of Intelligence</title>
        <description>&lt;p&gt;What was Albert Einstein’s IQ? Many sources online will tell you it was 160. But a quick foray into the supporting evidence for this number reveals that most sources have no scientific proof of Einstein’s IQ score. In fact, 160 may just be a relic of the scale used for measurement: WAIS-IV (Wechsler Adult Intelligence Scale 4), probably the most common IQ scoring system, happens to have a max score of — you guessed it — 160. Einstein could be the dictionary definition of genius in today’s society, yet we don’t even know his IQ. How, then, can we be sure of his intelligence?&lt;/p&gt;

&lt;p&gt;Well, we could look at his creation of a revolutionary new way of understanding the world through theoretical physics. In addition, IQ is a construct related to but separate from intelligence. Given that IQ does not answer our question, how can we truly measure Albert Einstein’s intelligence?&lt;/p&gt;

&lt;p&gt;As many recent critics of IQ have noted (duly), intelligence is a highly complex trait that cannot be reduced to a single score. However, IQ does demonstrate some correlation with job success, as noted &lt;a href=&quot;https://www.inc.com/business-insider/why-iq-big-factor-future-success-job-performance-according-science-research.html&quot;&gt;by Inc magazine&lt;/a&gt;. That is not to say that &lt;em&gt;intelligence&lt;/em&gt; correlates to job success, however.&lt;/p&gt;

&lt;p&gt;What exactly is intelligence, how can we quantify it, and how does it differ from IQ? These are the questions this article will attempt to answer, based on psychological research. After outlining the broad types of intelligence, defining intelligence becomes even more problematic when examining the details. The cultural assumptions inherent in almost all attempts to measure intelligence lead to the formation of problems like exclusivity and perhaps even cultural supremacy.&lt;/p&gt;

&lt;h3 id=&quot;whats-the-difference-between-iq-and-intelligence&quot;&gt;What’s the difference between IQ and intelligence?&lt;/h3&gt;

&lt;p&gt;Beginning with some definitions will help us clarify this discussion. First, IQ (Intelligence Quotient) is an artificial score, much like a high score in Mario Kart, that measures a person’s ability to perform on certain metrics. With Mario Kart, these skills depend on a person’s ability to navigate complex terrain at a high pace, dodging banana peels and throwing turtle shells. IQ tests, meanwhile, measure a person’s aptitude for problem-solving and verbal and spatial skills. Simple enough.&lt;/p&gt;

&lt;p&gt;Intelligence, however, has an deceptively simple definition. Oxford dictionary defines intelligence as “the ability to acquire and apply knowledge and skills.” This statement actually encompasses a vast variety of cognitive skills: memory, flexibility, and focus, just to name a few. Critically, defining intelligence in this way implies its dependence on environmental factors, because evidence has demonstrated that education has a clear influence on an individual’s ability to learn. Environmentally-influenced intelligence is the type that IQ is attempting to measure.&lt;/p&gt;

&lt;p&gt;So how can we measure intelligence as an intrinsic trait, based in genetics? We start out by recognizing this type of intelligence as separate from the traditional idea of IQ. Let’s call it Intelligence A.&lt;/p&gt;

&lt;h3 id=&quot;intelligence-a-vs-intelligence-b-vs-intelligence-c&quot;&gt;Intelligence A vs. Intelligence B vs. Intelligence C&lt;/h3&gt;

&lt;p&gt;A more nuanced way of defining intelligence is to realize that there is more than one definition. In a book comparing genetic and environmental determinants of intelligence, Philip Vernon helps define three types of intelligence: Intelligence A is intrinsic. It depends on basic physiological factors like reaction time. Intelligence B includes the effects from the environment. It refers to the application of Intelligence A to the real world, and fits quite well with the Oxford definition of intelligence. Meanwhile, Intelligence C refers to the measurement of intelligence, as in IQ tests. Measured values of intelligence often correlate much more closely with Intelligence B, because it has closely matched the popular conception of intelligence for the last few decades.&lt;/p&gt;

&lt;p&gt;Why is this distinction useful? Intelligence B, while clearly correlated with success, depends on the way a society is structured. In other words, it varies widely between cultures, and therefore between people. In other words, attempts to measure Intelligence B are highly variable and require that a new test is developed for every different culture. Meanwhile, Intelligence A consists of biological skills that should not vary across cultures.&lt;/p&gt;

&lt;p&gt;So it’s not surprising that IQ tests correlate with success — they reflect traits valued by our society and are therefore strengthened by other success-enhancing factors like education and socioeconomic status. If we want to truly measure the influence of intelligence on success &lt;em&gt;irrespective of culture&lt;/em&gt;, we need to examine the biological basis of intelligence.&lt;/p&gt;

&lt;p&gt;What exactly does a test of this type look like? The twentieth-century psychologist Hans Eysenck, known especially for his theory of introversion and extroversion, gives a possible example in the form of AEP (Auditory Evoked Potential), a test that allows researchers to measure the reaction time of subjects. He cited preliminary studies that found at least a 0.83 correlation between the AEP results and those of a WAIS test (the standard IQ test mentioned earlier). Apparently, this level of correlation is higher than those between functionally similar IQ tests like the WAIS and Binet tests. However, the study finding this correlation was performed on a notably small sample of individuals; therefore, it poorly represents the vast diversity in levels of education and socioeconomic status around the world.&lt;/p&gt;

&lt;h3 id=&quot;the-cultural-result-of-defining-intelligence&quot;&gt;The cultural result of defining intelligence&lt;/h3&gt;

&lt;p&gt;As noted by &lt;a href=&quot;https://www.apa.org/monitor/feb03/intelligence&quot;&gt;this American Psychological Association (APA) cover story&lt;/a&gt;, traditional measures of intelligence translate quite poorly across borders, raising problematic implications for cross-cultural interaction — an IQ test as currently given encapsulates the traits that are considered intelligent &lt;em&gt;in a particular culture&lt;/em&gt;. If a person comes from a culture where those traits are not so valued, they may suddenly find themselves perceived as less intelligent for arbitrary cultural reasons. As noted earlier, IQ is correlated with success, so this cultural disparity may be a major factor behind the cultural barriers to success afflicting diverse modern societies.&lt;/p&gt;

&lt;p&gt;The APA cover story explains that many psychologists no longer believe in the idea that a test can be completely absent of cultural bias, and probably for good reason. After all, the tests they are thinking of measure &lt;em&gt;Intelligence B&lt;/em&gt;, which by definition encompasses cultural knowledge. Perhaps focusing instead on intelligence A as the standard definition for intelligence, as Hans Eysenck suggested, may be a better way to obviate cultural biases by directly measuring brain activity. Modern brain-scanning technology certainly makes this a promising alternative to current tests. As the world as a whole moves to adopt fair values that appreciate, rather than punish, diversity, intelligence, critical to economic success, should be reconceived in a form that transcends cultural boundaries, as Intelligence A.&lt;/p&gt;

&lt;h3 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h3&gt;

&lt;p&gt;Intelligence, as traditionally defined, represents the sum of myriad genetic and cultural factors, including reaction time, education, socioeconomic status, and so on. Also known as Intelligence B, this is the type of trait commonly measured by IQ tests. Isolating the purely biological elements of intelligence as Intelligence A demonstrates that intelligence does not have to be the politically loaded, culturally and economically insensitive term that it is now, that there is hope for refining our definition of intelligence as both a biological and cultural phenomenon. Only then can we fully acknowledge the potential for growth that our current paradigm ignores all too frequently.&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;

&lt;p&gt;Here are some works that I drew content from, other than those linked in the article:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Eysenck, H. J. (1988). The biological basis of intelligence. In S. H. Irvine &amp;amp; J. W. Berry (Eds.), Human abilities in cultural context (p. 87–104). Cambridge University Press. https://psycnet.apa.org/record/1988-98683-003&lt;/li&gt;
  &lt;li&gt;Wikipedia page on Intelligence Quotient: https://en.wikipedia.org/wiki/Intelligence_quotient&lt;/li&gt;
  &lt;li&gt;Oxford Dictionary definition of intelligence: https://www.lexico.com/definition/intelligence&lt;/li&gt;
  &lt;li&gt;Philip Vernon’s book on intelligence: https://trove.nla.gov.au/work/11823287?q&amp;amp;versionId=45253153&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;further-reading&quot;&gt;Further reading&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Definition of cultural intelligence from David C. Thomas: https://doi.org/10.1002/9781118785317.weom060051&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 15 Jan 2020 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/cultural-intelligence/</link>
        <guid isPermaLink="true">http://localhost:4000/cultural-intelligence/</guid>
        
        <category>intelligence</category>
        
        
        <category>psychology</category>
        
        <category>essays</category>
        
        <category>science</category>
        
      </item>
    
      <item>
        <title>Mood and Productivity, Pt. 1: Does happiness live up to the hype?</title>
        <description>&lt;p&gt;Today, Vincent Van Gogh is indisputably recognized as a gifted creative. In his lifetime, however, he was unsuccessful by nearly every measure of the word: his art was never commercially appreciated, and many of his contemporaries considered him a madman. Suffering from severe depression for his whole life, van Gogh famously severed part of his own left ear, after an argument prompted him to start hearing voices. When he was thirty-seven years old, van Gogh walked out into a field and shot himself with a revolver.&lt;/p&gt;

&lt;p&gt;Van Gogh represents the classic ideal of the tortured artist. Alienated, misunderstood, yet ruthlessly innovative. Strangely enough, he is not alone in this predicament. Some of history’s greatest creatives were notably depressed, including Ernest Hemingway (&lt;em&gt;The Old Man and the Sea&lt;/em&gt;, &lt;em&gt;A Farewell to Arms&lt;/em&gt;), Sylvia Plath (&lt;em&gt;The Bell Jar&lt;/em&gt;), and George Orwell (&lt;em&gt;1984&lt;/em&gt;, &lt;em&gt;Animal Farm&lt;/em&gt;). It’s enough to make one wonder if the trope of the tortured genius is not the exception but in fact is the rule.&lt;/p&gt;

&lt;p&gt;Our increasing understanding of neuroscience and psychology gives us revolutionary insights into how our brains work. This knowledge allows us to explore the surprising links between mood and productivity. Used properly, this knowledge could enhance creativity and work output, all without compromising life satisfaction. In this series of articles, I will draw on history and science to address a potentially controversial series of questions relating mood and productivity:&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;Is there any truth to the trope of the tortured genius?&lt;/li&gt;
  &lt;li&gt;How can happiness be enhanced?&lt;/li&gt;
  &lt;li&gt;What does happiness do for productivity?&lt;/li&gt;
  &lt;li&gt;Is negativity good for anything?&lt;/li&gt;
  &lt;li&gt;How can &lt;em&gt;negativity&lt;/em&gt; be enhanced?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;First off, let’s turn our attention to a hot topic of the moment: happiness. There is certainly great value to the pursuit of happiness, but neglecting the less desirable emotions may not be sustainable. Where should happiness be applied, and when does it hinder us more than it helps? Read on to find out.&lt;/p&gt;

&lt;h1 id=&quot;mood-and-productivity-part-one-what-is-happiness-good-for&quot;&gt;Mood and productivity, Part One: What is happiness good for?&lt;/h1&gt;

&lt;p&gt;In the modern world, there is no shortage of “positive psychology” books, videos, and courses promising to help people find happiness in life. All these sources take for granted that happiness is an ideal goal. Intuitively, it seems obvious: a happy life is a good life. And yet, a growing body of evidence demonstrates that happiness is just one facet in living a life of fulfilment. What follows is an attempt to question the assumptions of those who promise the “good life” through happiness alone by presenting a more nuanced and scientific perspective, along with a guide to the areas where happiness might be best applied and where other emotions are more effective.&lt;/p&gt;

&lt;h2 id=&quot;the-pragmatic-view&quot;&gt;The pragmatic view&lt;/h2&gt;

&lt;p&gt;To determine the usefulness of a positive mood in measurable terms, we need to somehow measure how “good at thinking” a person can be, then see if those metrics change for happy and sad people. How can we measure that? First, by looking at easily studied traits, like short-term memory, then by applying such specific knowledge to a broader concept like creativity.&lt;/p&gt;

&lt;p&gt;So how does happiness stack up on these metrics? Well, studies have demonstrated that there appears to be a link between positive mood and improved memory. Meanwhile, creativity is an area where being happier might not always improve performance.&lt;/p&gt;

&lt;h3 id=&quot;happiness-improves-short-term-memory&quot;&gt;Happiness improves short-term memory&lt;/h3&gt;

&lt;p&gt;Justin Storbeck, a psychology professor at the City University of New York, studies the link between emotion and cognition. In 2015, a study of his found that a positive mood increases &lt;em&gt;working memory capacity&lt;/em&gt;—that is, the more correct way of describing “short-term memory”—when compared to neutral and negative moods.&lt;/p&gt;

&lt;p&gt;The study considered both verbal and spatial memory. Undergrad students were first induced to have a certain mood: the happy group was shown a 5-minute clip from &lt;em&gt;Jerry Seinfeld: Stand up in New York&lt;/em&gt;, the negative group 5 minutes from &lt;em&gt;The Champ&lt;/em&gt; and the neutral group 5 minutes from &lt;em&gt;If Dolphins Could Talk&lt;/em&gt;. The participants were then instructed to complete a verbal task and an operation task. In the verbal task, participants were shown a list of 3, 5 or 7 words for 3 seconds each. Then—here’s the catch—the operation task interrupted their focus: after the last word was shown, participants were asked to analyze several math problems (e.g., “6/(3-2) = 0”) and indicate whether the equations were correct. Finally, they were asked to recall what words were presented in the verbal task, and in what order. The researchers then repeated the experiment, this time substituting the word-recall task for a task where participants memorize the locations of boxes presented in a grid.&lt;/p&gt;

&lt;p&gt;Earlier research seemed to indicate that positive moods were better for &lt;em&gt;verbal&lt;/em&gt; memory, whereas negativity enhances &lt;em&gt;spatial&lt;/em&gt; memory. In this study, however, the math problems served to help measure the persistence of memories through an unrelated task. This method revealed that a positive mood improved participants’ performance on both verbal and spatial memory, supporting the idea that happiness is good for remembering all kinds of things. Storbeck goes on to cite a possible neurological explanation: “positive mood increases dopamine, which is an important underlying biological mechanism for executive control and working memory.”&lt;/p&gt;

&lt;p&gt;While focused on a relatively narrow segment of the population (undergrad students in New York), this study’s implications for society at large could be enormous: if happy people truly think better than sad people, governments should consciously invest in the happiness of their citizens. Likewise, companies should recognize (as many already have) that a happy employee tends to be a productive employee. In this light, promoting positive psychology is not just a moral obligation but a pragmatic choice with quantifiable benefits.&lt;/p&gt;

&lt;p&gt;But that’s assuming that Storbeck’s findings with regard to working memory capacity hold true for all the other metrics of cognition. Is that really the case? Let’s take a closer look by examining another measure of brain function: creativity. In today’s high tech economy, innovation is crucial to economic growth. Creativity is a requirement for innovators, and the question for many ambitious individuals is how to nurture and sustain creativity. Specifically relevant to our current discussion is how mood, positive or negative, can be leveraged to increase creativity.&lt;/p&gt;

&lt;h3 id=&quot;happiness-can-improve-or-hurt-creativity&quot;&gt;Happiness can improve or hurt creativity&lt;/h3&gt;

&lt;p&gt;Creativity is often thrown around as a blanket description for a complex batch of useful brain functions. But what is it exactly? For now, let’s call it the production and execution of original ideas.&lt;/p&gt;

&lt;p&gt;Depression, obviously, is not a sustainable method of creativity. In fact, depression debilitates an individual, and we should not wish on anyone the fate of the tortured geniuses like Vincent Van Gogh and Sylvia Plath. Mild sadness, however, is a normal and healthy emotion that plays a vastly underappreciated role in our lives. In fact, research completed by professor Joseph P. Forgas at the University of New South Wales has determined that sadness can, among other things, &lt;a href=&quot;https://greatergood.berkeley.edu/article/item/four_ways_sadness_may_be_good_for_you&quot;&gt;improve (long-term) memory, improve judgement, and increase motivation&lt;/a&gt;. Happiness, meanwhile, caused the opposite to occur in these studies, diminishing the participants’ abilities to perform these critical cognitive functions.&lt;/p&gt;

&lt;p&gt;So maybe happier people aren’t necessarily smarter people. Barring the negative extreme of depression, a little bit of sadness can go a long way in improving performance at certain tasks. In other words, sadness can be an asset in pursuing the second part of creativity: the execution of ideas. But what about the production of original ideas?&lt;/p&gt;

&lt;p&gt;Here, evidence favors the happy. A 2008 meta-analysis of mood-creativity research revealed that happiness produces a measurable increase in a person’s creativity, whereas emotions like fear and anxiety are linked to &lt;em&gt;lower&lt;/em&gt; levels of creativity. Meanwhile, less active moods like relaxation and sadness demonstrated little correlation with creativity. In other words, being happy allows you to come up with more original ideas, which are the first requirement of creativity.&lt;/p&gt;

&lt;p&gt;It seems that happiness is good for producing ideas, while sadness can help us follow through with them. Both are critical stages of the creative process: Ideation is nothing without execution. Execution is worthless without ideation. In the same way, perhaps, happiness is nothing without sadness, and the full array of human emotion as well. Amidst the deafening hype of positive psychology, it’s often useful to slow down and remind ourselves that there are specific areas where happiness is appropriate, and others where sadness might serve us better. “Being happy” is just one element of the diverse source of fulfilment.&lt;/p&gt;

&lt;p&gt;Rather than using our increasing understanding of our minds as a weapon to promote an ideology, we can apply a rigorous approach of questioning, so that, even in this nuanced mass of information, we can eventually puzzle out a better way of life. When we do discover it—given the spectacular complexity of human psychology—we can probably rest assured that the secret to a good life doesn’t fit into a soundbite.&lt;/p&gt;

&lt;h2 id=&quot;notes&quot;&gt;Notes&lt;/h2&gt;

&lt;p&gt;Here are some works that I drew content from:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;a href=&quot;https://en.wikipedia.org/wiki/Vincent_van_Gogh&quot;&gt;Vincent Van Gogh’s Wikipedia page&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;The &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pubmed/25947579&quot;&gt;finding that happiness increases working memory capacity&lt;/a&gt; is presented by Storbeck and Maswood.&lt;/li&gt;
  &lt;li&gt;Baas, M., De Dreu, C. K. W., &amp;amp; Nijstad, B. A. (2008). A meta-analysis of 25 years of mood-creativity research: Hedonic tone, activation, or regulatory focus? Psychological Bulletin, 134(6), 779–806. &lt;a href=&quot;https://doi.org/10.1037/a0012815&quot;&gt;https://doi.org/10.1037/a0012815&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;further-reading&quot;&gt;Further reading&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;Catherine Weismann-Arcache and Sylvie Tordjman have studied the relationship between depression and high intellectual potential in children. Their article can be found at &lt;a href=&quot;https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3356869/&quot;&gt;nih.gov&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;This Fast Company article provides an executive summary of scientific results promoting the usefulness of negativity: &lt;a href=&quot;https://www.fastcompany.com/3038199/the-positive-results-of-being-negative&quot;&gt;https://www.fastcompany.com/3038199/the-positive-results-of-being-negative&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;&lt;a href=&quot;https://www.toptenz.net/top-10-tortured-artists.php&quot;&gt;A top-ten list of some tortured artists&lt;/a&gt;.&lt;/li&gt;
  &lt;li&gt;Karuna Subramaniam and Sophia Vinogradov &lt;a href=&quot;https://www.frontiersin.org/articles/10.3389/fnhum.2013.00452/full&quot;&gt;address links between happiness and improved cognition&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
        <pubDate>Wed, 08 Jan 2020 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/mood-and-productivity-one/</link>
        <guid isPermaLink="true">http://localhost:4000/mood-and-productivity-one/</guid>
        
        <category>happiness</category>
        
        
        <category>psychology</category>
        
        <category>essays</category>
        
        <category>science</category>
        
      </item>
    
      <item>
        <title>Version Management with a JavaScript Service Worker</title>
        <description>&lt;p&gt;The JavaScript service worker API is a way to give online web apps offline functionality. By running in the background of the browser, service workers are able to cache important files and give users a smooth offline experience.&lt;/p&gt;

&lt;h2 id=&quot;what-is-a-service-worker&quot;&gt;What is a service worker?&lt;/h2&gt;
&lt;p&gt;A service worker is a script (i.e., a JavaScript file) that the browser runs in the background. It can be used for features such as offline apps and push notifications. In the case of an offline app, service workers can be used to determine whether a new version of the app is available as an update.&lt;/p&gt;

&lt;p&gt;A tip for Chrome users: to see what service workers are currently running in your browser, open Developer Tools (F12), click “Application” on the top bar, and click “Service Workers” on the sidebar that comes up.&lt;/p&gt;

&lt;h2 id=&quot;how-a-service-worker-works&quot;&gt;How a service worker works&lt;/h2&gt;
&lt;p&gt;A service worker has three steps in its lifecycle:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Registration&lt;/li&gt;
  &lt;li&gt;Installation&lt;/li&gt;
  &lt;li&gt;Activation&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Once these three steps are finished, the service worker stays in the browser indefinitely, even if the user refreshes the page, making it useful for storing information in the cache to be used offline. Read more on the service worker lifecycle &lt;a href=&quot;https://developers.google.com/web/fundamentals/primers/service-workers/lifecycle&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Here is a &lt;a href=&quot;https://developers.google.com/web/fundamentals/primers/service-workers&quot;&gt;guide from Google&lt;/a&gt; detailing the code you need to set up a service worker.&lt;/p&gt;

&lt;h2 id=&quot;using-service-workers-for-version-management&quot;&gt;Using service workers for version management&lt;/h2&gt;
&lt;p&gt;Each time a page is refreshed, the service worker file is checked for any changes. If even a byte has changed, a new service worker is loaded, ready to place the old one whenever the &lt;code class=&quot;highlighter-rouge&quot;&gt;skipWaiting&lt;/code&gt; event is triggered. We can take advantage of this fact by changing the service worker file in each new version of the app.&lt;/p&gt;

&lt;p&gt;Typically, the top of a service worker file will have something like the following variable declaration:
    const CACHE_NAME = ‘my-site-static-v1’;&lt;/p&gt;

&lt;p&gt;Each time you create a new version of the app, just update the service worker script, changing ‘v1’ to whatever the new version is (e.g., ‘v4.5.2’) and a new service worker will be created automatically.&lt;/p&gt;

&lt;p&gt;If you don’t want to do this manually, you can replace the text in your service worker’s JavaScript file automatically on build. The specific implementation of this differs depending on what system the app is using for build tasks.&lt;/p&gt;

&lt;p&gt;Note: if you happen to be using &lt;code class=&quot;highlighter-rouge&quot;&gt;grunt&lt;/code&gt; for build tasks, make sure to use &lt;code class=&quot;highlighter-rouge&quot;&gt;grunt-text-replace&lt;/code&gt; to replace the version number (&lt;a href=&quot;https://www.npmjs.com/package/grunt-text-replace&quot;&gt;installation instructions for grunt-text-replace&lt;/a&gt;), as &lt;code class=&quot;highlighter-rouge&quot;&gt;grunt-text-replace&lt;/code&gt; supports in-place overwriting, which means you can directly edit the source file for your service worker. All of the other text-replace modules I found for grunt only allow editing in the build files.&lt;/p&gt;

&lt;h3 id=&quot;fetching-the-new-service-workers&quot;&gt;Fetching the new service workers&lt;/h3&gt;
&lt;p&gt;Now that you have a new service worker for each new version of the app, the user should be prompted to fetch the new version. This involves triggering the &lt;code class=&quot;highlighter-rouge&quot;&gt;skipWaiting&lt;/code&gt; event on a service worker and reloading the page. A working implementation of this feature can be found &lt;a href=&quot;https://deanhume.com/displaying-a-new-version-available-progressive-web-app/&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Service workers are not easy to deal with, but they can enable effective version management with offline web apps. This tutorial represents just one of the many ways version management can be implemented in an offline web app.&lt;/p&gt;
</description>
        <pubDate>Wed, 01 Jan 2020 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/service-workers-for-version-management/</link>
        <guid isPermaLink="true">http://localhost:4000/service-workers-for-version-management/</guid>
        
        <category>javascript</category>
        
        
        <category>programming</category>
        
        <category>tutorials</category>
        
      </item>
    
      <item>
        <title>Oatmeal and Emergence: How a whole can be greater than the sum of its parts</title>
        <description>&lt;p&gt;Oatmeal. At best, it is a nutritious and filling breakfast. At worst, a sloppy and unappetizing gruel. In short, oatmeal exhibits stunning diversity. However, amidst all these seemingly disparate varieties of oatmeal lies a surprising commonality, one that may leave you thinking about your breakfast long after the last bite.&lt;/p&gt;

&lt;p&gt;Imagine you got up early to prepare breakfast, and you’re cooking a bowl of oatmeal, as one does. Only today’s oatmeal is different—today, you heat up the water and get out the bag of oatmeal, to find that just one singular oat remains in the bag. Persisting in the face of adversity, you decide to cook the oatmeal anyways.&lt;/p&gt;

&lt;p&gt;As usual, you turn down the fire and let the oatmeal simmer until it reaches the desired consistency, that perfect level of softness and coherence that we all know and love. But it never does. Try as you might, a singular oat will never achieve that consistency, because the lonely flake has no companions to stick to.&lt;/p&gt;

&lt;p&gt;This brings to mind a scientific property called emergence: the idea that a whole can be greater than the sum of its parts. Truly great-tasting oatmeal reflects something more than just the taste of individual oats combined—it is the interaction between oats that creates oatmeal’s hallmark texture. The texture of oatmeal is what’s known as an emergent property.&lt;/p&gt;

&lt;p&gt;Breakfast foods are not the only things that demonstrate emergence.&lt;/p&gt;

&lt;p&gt;Water, for example, is very similar to cooked oatmeal in that water molecules like to stick to each other. Water’s intermolecular interactions give rise to emergent properties like cohesion, high specific heat, and evaporative cooling. Without emergence, we might not be alive today.&lt;/p&gt;

&lt;p&gt;Our brains also have emergent properties. Looking at an individual neuron, it is impossible to explain how thoughts might be formed. It’s only when we look at the brain as a system of neurons that we can study how these remarkable organs can process information, form memories, and read articles about oatmeal.&lt;/p&gt;

&lt;p&gt;The animal world is full of emergence. Ant colonies, along with those of other social insects (and perhaps even humans), are especially interesting in their collective intelligence. An individual ant/bee/human is relatively unintelligent. Put together, the colony of ants/bees/humans can form tunnel networks, scout for food, and even invent the Internet.&lt;/p&gt;

&lt;p&gt;But what’s so special about emergence? Why do we care?&lt;/p&gt;

&lt;p&gt;Emergence while mentioned in earlier texts, didn’t begin to take on serious scientific interest until the late 19th century. In the early days of science, reductionism, the idea that anything can be understood if we can break it down into its simpler components, was the prevailing mode of thought. If you want to know how a car works, take it apart and you’ll see the engine, battery, radiator, and so on, each with a specific function that contributes logically to the functioning of the car. Reductionism works for simple examples like motor vehicles, but breaks down when we start to analyze many natural systems.&lt;/p&gt;

&lt;p&gt;What if you want to know how the human brain works? Nothing in an individual neuron suggests the ability to think. Taking a brain apart doesn’t help us understand it. Here, we need to recognize that cognition is an emergent property—rather than analyzing brain cells, we can only consider the functioning of the brain as a whole.&lt;/p&gt;

&lt;p&gt;Some things can’t be explained as a combination of parts.&lt;/p&gt;

&lt;p&gt;Your morning oatmeal might be delicious, or disgusting, or one of the million options in between. Nevertheless, something magical happens every time oats (plural) are cooked. An unsuspecting individual, the singular oat, has potential for greatness, if only allowed to join a whole and form emergent properties.&lt;/p&gt;

&lt;p&gt;Behind a humble breakfast food lies a scientific principle essential to our understanding of the world. Simple as it may be, oatmeal is symbolic of the power of a whole to be greater than the sum of its parts, giving us humans (plural) a good reason to play with our food in the morning.&lt;/p&gt;
</description>
        <pubDate>Tue, 31 Dec 2019 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/oatmeal-and-emergence/</link>
        <guid isPermaLink="true">http://localhost:4000/oatmeal-and-emergence/</guid>
        
        <category>emergence</category>
        
        
        <category>food</category>
        
        <category>essays</category>
        
        <category>science</category>
        
      </item>
    
      <item>
        <title>How to Download an Image as a PDF using jsPDF</title>
        <description>&lt;p&gt;PDF documents are great because they preserve the format of a page. In other words, the content in a PDF document typically does not get distorted, pixelated, stretched, or compressed. Because of this, an image, once it’s been converted to a PDF, will typically preserve its dimensions and clarity. Making sure an image always looks sharp and focused is almost always a concern of designers, developers, and even just regular old people. When making a site that deals with images, developers may increasingly consider implementing “Save as PDF” as an attractive option for exporting an image. That’s why I decided to document some of the successes and struggles I encountered while working on this feature.&lt;/p&gt;

&lt;p&gt;My goal was to add a “Save as PDF” option to an image processing web app. The dependency I chose to use was &lt;a href=&quot;https://www.npmjs.com/package/jspdf&quot;&gt;jspdf&lt;/a&gt;, which is a free library that lets you use Javascript to generate PDFs of all kinds. Because the library is not designed specifically for converting images to PDF documents, the main struggle I faced was creating a PDF document with dimensions that matched those of the image, so I could avoid those distasteful white margins and unintentionally cropped images that would result from using a standard-sized page. Here’s the way I set up jsPDF to make sure images could be smoothly downloaded as PDFs:&lt;/p&gt;

&lt;h1 id=&quot;set-up-jspdf&quot;&gt;Set up jsPDF&lt;/h1&gt;
&lt;p&gt;Follow the instructions from &lt;a href=&quot;https://www.npmjs.com/package/jspdf&quot;&gt;npm&lt;/a&gt;. The easiest way to use jsPDF in a web-based project is to add a script tag linking to the cloud:
        &lt;script src=&quot;https://cdnjs.cloudflare.com/ajax/libs/jspdf/1.5.1/jspdf.debug.js&quot; integrity=&quot;sha384-THVO/sM0mFD9h7dfSndI6TS0PgAGavwKvB5hAxRRvc0o9cPLohB0wb/PTA7LdUHs&quot; crossorigin=&quot;anonymous&quot;&gt;&lt;/script&gt;&lt;/p&gt;

&lt;h1 id=&quot;convert-the-image-to-a-data-uri&quot;&gt;Convert the image to a data URI&lt;/h1&gt;
&lt;p&gt;For now, jsPDF can only add an image to a PDF if the image is in &lt;a href=&quot;https://en.wikipedia.org/wiki/Data_URI_scheme&quot;&gt;data URI format&lt;/a&gt;. For the web app I was working on, the image I wanted to download already had a data URI as its source. In other words, it looked something like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;  &amp;lt;img src=&quot;data:image/png;base64,iVBORw0KGgoAAA
  ANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4
  //8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU
  5ErkJggg==&quot; alt=&quot;Red dot&quot; /&amp;gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;(Example taken from &lt;a href=&quot;https://en.wikipedia.org/wiki/Data_URI_scheme#HTML&quot;&gt;Wikipedia&lt;/a&gt;)&lt;/p&gt;

&lt;p&gt;This example would show up as a red dot: &lt;img src=&quot;data:image/png;base64,iVBORw0KGgoAAA ANSUhEUgAAAAUAAAAFCAYAAACNbyblAAAAHElEQVQI12P4 //8/w38GIAXDIBKE0DHxgljNBAAO9TXL0Y4OHwAAAABJRU 5ErkJggg==&quot; alt=&quot;Red dot&quot; /&gt;&lt;/p&gt;

&lt;p&gt;If your image is not already a data URI, it’s relatively easy to convert it. First, put the image on a canvas. Next, call canvas.toDataURL() to get the data URI of the image. You can find a great implementation of this method &lt;a href=&quot;https://davidwalsh.name/convert-image-data-uri-javascript&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;h1 id=&quot;generate-the-pdf-based-on-the-data-uri&quot;&gt;Generate the PDF based on the data URI&lt;/h1&gt;
&lt;p&gt;The key to downloading an image as a PDF is to get the right image dimensions, to make sure the PDF page dimensions match those of the image.
In my case, the image dimensions were conveniently stored in order to facilitate image processing, but in a more general case you could get the image dimensions using &lt;code class=&quot;highlighter-rouge&quot;&gt;image.naturalHeight&lt;/code&gt; and &lt;code class=&quot;highlighter-rouge&quot;&gt;image.naturalWidth&lt;/code&gt;:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;// Download the given image URL as a PDF file.
function savePDF(imageDataURL) {
  // Get the dimensions of the image.
  var image = new Image();

  image.onload = function() {
    let pageWidth = image.naturalWidth;
    let pageHeight = image.naturalHeight;

    // Create a new PDF with the same dimensions as the image.
    const pdf = new jsPDF({
      orientation: pageHeight &amp;gt; pageWidth ? &quot;portrait&quot;: &quot;landscape&quot;,
      unit: &quot;px&quot;,
      format: [pageHeight, pageWidth]
    });

    // Add the image to the PDF with dimensions equal to the internal dimensions of the page.
    pdf.addImage(imageDataURL, 0, 0, pdf.internal.pageSize.getWidth(), pdf.internal.pageSize.getHeight());

    // Save the PDF with the filename specified here:
    pdf.save(&quot;index.pdf&quot;);
  }

  image.src = imageDataURL;
} Note: naturalWidth and naturalHeight are only supported in modern browsers. [These are the browsers that support these properties.](https://caniuse.com/#feat=img-naturalwidth-naturalheight)
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;And that’s how to use Javascript to give users the option to download an image as a PDF. To summarize:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;Set up jsPDF.&lt;/li&gt;
  &lt;li&gt;Make sure the image you want to download is in data URI form.&lt;/li&gt;
  &lt;li&gt;Use jsPDF to add the image to a new PDF document.&lt;/li&gt;
&lt;/ol&gt;

&lt;h4 id=&quot;a-footnote-data-url-vs-data-uri&quot;&gt;A footnote: Data URL vs. Data URI&lt;/h4&gt;
&lt;p&gt;The form of image data dealt with in this tutorial can be called both a data URL and a data URI. This is because URLs (Uniform Resource Locators) are a subset of URIs (Uniform Resource Identifiers). As to whether HTML data URIs can be considered URLs,&lt;/p&gt;
</description>
        <pubDate>Thu, 12 Dec 2019 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/how-to-download-an-image-as-a-pdf-using-jsPDF/</link>
        <guid isPermaLink="true">http://localhost:4000/how-to-download-an-image-as-a-pdf-using-jsPDF/</guid>
        
        <category>javascript</category>
        
        
        <category>programming</category>
        
        <category>tutorials</category>
        
      </item>
    
      <item>
        <title>How to Scan a Barcode with Flutter</title>
        <description>&lt;p&gt;Here’s how to set up a simple barcode scanning function, starting from a basic flutter app. In this tutorial we’ll be using the &lt;a href=&quot;https://pub.dev/packages/barcode_scan&quot;&gt;barcode_scan Flutter package&lt;/a&gt;. The package site has its own tutorial, but the tutorial has some outdated information, so I thought I’d try and correct that here.&lt;/p&gt;

&lt;h1 id=&quot;set-up-the-configuration-files&quot;&gt;Set up the configuration files&lt;/h1&gt;
&lt;p&gt;As listed on &lt;a href=&quot;https://pub.dev/packages/barcode_scan&quot;&gt;barcode_scan’s about page&lt;/a&gt; on Dart Pub, start by making the following changes:&lt;/p&gt;

&lt;h2 id=&quot;for-android&quot;&gt;For Android:&lt;/h2&gt;

&lt;p&gt;Add this line to your AndroidManifest.xml to request permission to use the user’s camera:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;    &amp;lt;uses-permission android:name=&quot;android.permission.CAMERA&quot; /&amp;gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Add this line (to allow the BarcodeScanner activity) to your AndroidManifest.xml. Do NOT modify the name.&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;    &amp;lt;activity android:name=&quot;com.apptreesoftware.barcodescan.BarcodeScannerActivity&quot;/&amp;gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Install the Kotlin plugin for Android Studio or your default editor&lt;/p&gt;

&lt;p&gt;Edit your project-level build.gradle file to look like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;      buildscript {
          ext.kotlin_version = '1.2.31'
          ...
          dependencies {
              ...
              classpath &quot;org.jetbrains.kotlin:kotlin-gradle-plugin:$kotlin_version&quot;
          }
      }
      ...
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Edit your app-level build.gradle file to look like this:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;    apply plugin: 'kotlin-android'
    ...
    dependencies {
        implementation &quot;org.jetbrains.kotlin:kotlin-stdlib-jre7:$kotlin_version&quot;
        ...
    }
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;In your pubspec.yaml file, add &lt;code class=&quot;highlighter-rouge&quot;&gt;barcode_scan: ^1.0.0&lt;/code&gt; to the list of dependencies, as follows:&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;    dependencies:
      flutter:
        sdk: flutter
      # other dependencies...
      barcode_scan: ^1.0.0

Note: for some reason many tutorials, including that of the publishers themselves, say to add `barcode_scan: ^0.0.3` to your pubspec.yaml file. This tends to cause problems because 0.0.3 is an unsupported version of this dependency.
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Click “Packages get” in Android Studio or run flutter packages get in your project folder.&lt;/p&gt;

&lt;h2 id=&quot;for-ios&quot;&gt;For iOS:&lt;/h2&gt;
&lt;p&gt;To use on iOS, you must add the the camera usage description to your Info.plist&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;    &amp;lt;key&amp;gt;NSCameraUsageDescription&amp;lt;/key&amp;gt;
    &amp;lt;string&amp;gt;Camera permission is required for barcode scanning.&amp;lt;/string&amp;gt;
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;write-the-testing-code&quot;&gt;Write the testing code&lt;/h1&gt;
&lt;p&gt;The package barcode_scan should now be successfully installed and configured in your flutter application. Now all that remains is to use the package in your app!&lt;/p&gt;

&lt;p&gt;Outside of the formatting, the key to this example is the call to &lt;code class=&quot;highlighter-rouge&quot;&gt;BarcodeScanner.scan()&lt;/code&gt;, which uses the imported package &lt;code class=&quot;highlighter-rouge&quot;&gt;barcode_scan&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&quot;completed-code-in-maindart&quot;&gt;Completed code in main.dart&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;table class=&quot;rouge-table&quot;&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;rouge-gutter gl&quot;&gt;&lt;pre class=&quot;lineno&quot;&gt;1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;rouge-code&quot;&gt;&lt;pre&gt;import 'dart:async';
import 'package:barcode_scan/barcode_scan.dart';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';

void main() {
  runApp(new MyApp());
}

class MyApp extends StatefulWidget {
  @override
  _MyAppState createState() =&amp;gt; new _MyAppState();
}

class _MyAppState extends State&amp;lt;MyApp&amp;gt; {
  String barcode = &quot;&quot;;

  @override
  initState() {
    super.initState();
  }

  @override
  Widget build(BuildContext context) {
    return new MaterialApp(
      theme: ThemeData(
        primarySwatch: Colors.blue,
      ),
      home: Scaffold(
          appBar: AppBar(
            title: Text('Barcode Scanner'),
          ),
          body: Center(
            child: Column(
              children: &amp;lt;Widget&amp;gt;[
                Padding(
                  padding: const EdgeInsets.all(8.0),
                  child: Text(&quot;Press the button to scan an item:&quot;),
                ),
                Container(
                  child: RaisedButton(onPressed: scan, child: Text(&quot;Scan&quot;)),
                  padding: const EdgeInsets.all(8.0),
                ),
                Padding(
                  padding: const EdgeInsets.all(8.0),
                  child: Text(barcode),
                ),
              ],
            ),
          )),
    );
  }

  //scan a barcode, store result in this.barcode
  Future scan() async {
    try {
      //use barcode_scan to scan the barcode
      String barcode = await BarcodeScanner.scan();

      //if the barcode has been obtained, display it
      if (barcode.length &amp;gt; 0)
        setState(
            () =&amp;gt; this.barcode = &quot;The barcode you scanned was: &quot; + barcode);
    } on PlatformException catch (e) {
      if (e.code == BarcodeScanner.CameraAccessDenied) {
        setState(() {
          this.barcode = 'Camera permission was not granted';
        });
      } else {
        setState(() =&amp;gt; this.barcode = 'Unknown error: $e');
      }
    } on FormatException {
      //the user probably just pressed the back button, no need to print an error message
      setState(() =&amp;gt; this.barcode = '');
    } catch (e) {
      setState(() =&amp;gt; this.barcode = 'Unknown error: $e');
    }
  }
}
&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Tue, 26 Nov 2019 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/how-to-scan-a-barcode-in-flutter/</link>
        <guid isPermaLink="true">http://localhost:4000/how-to-scan-a-barcode-in-flutter/</guid>
        
        <category>flutter</category>
        
        <category>dart</category>
        
        
        <category>programming</category>
        
        <category>tutorials</category>
        
      </item>
    
      <item>
        <title>How to make toast</title>
        <description>&lt;p&gt;Though not everyone can make a juicy Beef Wellington or perfectly crunchy macarons, well-toasted bread should be something we can all have. After all, the materials are so simple: a toaster and a slice of bread. It couldn’t be so hard, right? Wrong.&lt;/p&gt;

&lt;p&gt;In fact, perfectly-toasted bread is not merely a simple daily task; it is a science. Consistently creating a crispy, golden-brown exterior and a soft, flavorful interior requires extreme care, from the cooking time to the model of toaster, to even the way the bread is sliced.&lt;/p&gt;

&lt;p&gt;Fortunately for us, this delicacy has been meticulously researched. We even know how to make toast without a toaster. Unfortunately, reading all that information about toast would take a lifetime, so here’s a simple flowchart for all your toast-making needs:&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/toast-flowchart.jpg&quot; alt=&quot;Toast flowchart&quot; /&gt;&lt;/p&gt;

&lt;p&gt;So now you know more than you ever wanted to know about making toast. Time to revel in your enlightenment and savor the glorious golden-brown toast. Pretty soon, you’ll be making the perfect toast for lunch and dinner, when friends come over, when you’re hosting a meal for the General Assembly of the United Nations! Or maybe just for breakfast.&lt;/p&gt;
</description>
        <pubDate>Sun, 09 Sep 2018 00:00:00 -0500</pubDate>
        <link>http://localhost:4000/how-to-make-toast/</link>
        <guid isPermaLink="true">http://localhost:4000/how-to-make-toast/</guid>
        
        
        <category>food</category>
        
        <category>tutorials</category>
        
      </item>
    
      <item>
        <title>Communication Between Trees</title>
        <description>&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;All over the world, trees stand guard over their forest ecosystems, like still, silent, sentinels. However, these trees might not be so silent after all. There is evidence that trees can communicate and help each other, uprooting the traditional idea of competition between trees as the only way they adapt.&lt;/p&gt;

&lt;h2 id=&quot;the-importance-of-fungi&quot;&gt;The Importance of Fungi&lt;/h2&gt;
&lt;p&gt;There are many adaptations and structures that make communication and aid between trees possible. Many of these structures are ectomycorrhizal fungi, members a type of fungi that have a symbiotic relationship with trees and partially live within the tree roots. One study found that thirty-nine, give or take one percent, of total soil microbial biomass was contributed by ectomycorrhizal fungi, showing the important role of mycorrhizal networks in the below-ground transfer of carbon between trees (Högberg, Mona N., et al. 491). This evidence explains that the ectomycorrhizal fungi are an important part of the ecosystem. These mycorrhizal fungi form underground networks of mycelium, root-like structures. Specifically, Laccaria bicolor is a species of ectomycorrhizal fungi that has been studied. Researchers discovered that the genome of Laccaria bicolor increased in the areas of protein-protein interaction and signal transduction mechanisms, which could signal specialization for the purpose of symbiosis” (Martin, F., et al. 88). They also observed other interesting features of the species’ genome and life: “expression of several SSPs was downregulated in ectomycorrhizal root tips, suggesting a complex interplay between these secreted proteins in the symbiosis interaction” (Martin, F., et al. 88). These results show that the fungi L. bicolor may use small secreted proteins to aid in their mutualistic relationship with trees. In conclusion, “the rich assortment of MISSPs[mycorrhiza-induced small secreted proteins] may therefore act as effector proteins to manipulate host cell signalling or to suppress defence pathways during infection” (Martin, F., et al. 88). L. bicolor certainly contributes greatly to the networks between trees, and trees also help the fungi. One group researching fungi found that ”the C [carbon] used for production of these sporocarps is from tree below-ground allocation in the late season” (Högberg, Mona N., et al. 490). Trees place carbon underground and send some to other trees, while some of this carbon goes to benefit the fungi. Ectomycorrhizae are the main structures in the the networks connecting trees.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/mushroom.jpg&quot; alt=&quot;Mushrooms&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;forms-of-communication&quot;&gt;Forms of Communication&lt;/h2&gt;
&lt;p&gt;Trees can communicate a variety of signals and materials. One of the most common of these materials is carbon, which is transferred through root connections between trees. The transfer of carbon has been shown in numerous studies (Simard, Perry 581). Trees also send each other defense signals, though one study suggests that the communication of defense signals may not be through the root networks: “Even though root connections can trigger physiological responses to defoliation in non-defoliated aspen suckers (Baret and DesRochers 2011), our results suggest that these root pathways do not automatically lead to induction of defensive traits that are expressed in plants directly under herbivore attack” (Jelínková, Hana, et al. 1354).  Rather, it seems that the expression of defense signals and responses is regulated through airborne volatiles. The same study found that there was an upregulation of dihydroflavonol reductase and Kunitz trypsin inhibitor, two signs of defense response, in sibling ramets, whether they were connected to the control group or the wound-treated plants. This suggests a role of herbivore-induced plant volatiles (HIPV) in spreading defense signals throughout the population (Jelínková, Hana, et al. 1353). Communications are sent through the air as well as the roots. Trees can send carbon and defense signals to each other.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;“Trees send each other defense signals… through airborne volatiles.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;further-evidence-of-tree-communication&quot;&gt;Further Evidence of Tree Communication&lt;/h2&gt;
&lt;p&gt;Trees help each other in other ways as well, creating mutualistic relationships between them. In order to continue the genetic lineage, clonal parent plants will help out their connected ramets. In one species of a water plant, clonal parent plants were found to transfer 10% of their carbon to connected ramets, and this has been shown to increase the survival and growth of the ramets (Warembourg, Roy 1459).  One group of Canadian scientists researched the relationship between Douglas Fir (Pseudotsuga menziesii) and Paper Birch (Betula papyrifera) using radioactive and stable isotopes of carbon. They noted that “Net transfer from B. papyrifera to P. menziesii was associated with whole-seedling net photosynthetic rates 1.5 and 4.3 times greater for B. papyrifera than for P. menziesii in full light and deep shade, respectively, and foliar nitrogen concentrations twice as great for B. papyrifera as for P. menziesii” (Simard, Perry 580). In other words, the birch helped out the fir because the fir was converting less energy from sunlight into glucose. They concluded that “when P. menziesii seedlings are establishing and growing in the shade of illuminated B. papyrifera in natural, mixed communities, they may benefit directly from their association with B. papyrifera through supplemental gains in transferred carbon” (Simard, Perry 581). Trees benefit from their relationships with each other.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;/assets/images/birch.jpg&quot; alt=&quot;Mushrooms&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;consequences-of-tree-communication&quot;&gt;Consequences of Tree Communication&lt;/h2&gt;
&lt;p&gt;In general, trees that communicate and have mutualistic relationships with other trees are more successful than other trees. A group of researchers studying Canadian pine forests found that the late-season increase in the carbon allocation of boreal pine forests doubled the increase found in a study of temperate poplar forests, and this could be the reason for the decrease in leaf area of poplars during the late season (Högberg, Mona N., et al. 490). The trees that communicated in the form of carbon had larger leaf area later in the season. There is a growing body of evidence showing that trees communicate, and that the communication could be a large part of their survival strategies. However, there is still reasonable room for doubt, because of the proven fallibility of science, and the principles governing scientific reasoning. Pioneering studies may prove to be flawed, and many biologists acknowledge this, including the group studying colonies of aspen: “To clarify the role of aspen root networks in anti-herbivore defense, further studies employing real insect feeding are needed” (Jelínková, Hana, et al. 1354). In the world of science, study results are always taken with skepticism, as they should be, and the relatively new science of tree communication should be treated as such. However, so far, the trees can be seen to benefit from communication.&lt;/p&gt;

&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Trees can likely communicate in ways that are beneficial to them, through carbon transfer, airborne volatiles, and networks of fungi. Behind the quiet exterior of a stand of trees, there may be a lively conversation taking place. It just takes a careful listener to hear it.&lt;/p&gt;

&lt;h2 id=&quot;works-cited&quot;&gt;Works Cited&lt;/h2&gt;

&lt;p&gt;Albert, P., F. R. Warembourg, and J. Roy. “Transport of Carbon among Connected Ramets of
Eichhornia Crassipes (Pontederiaceae) at Normal and High Levels of CO2.”American Journal of Botany 78 (1991): 1459-466. United States Department of Agriculture National Agricultural Library. United States Department of Agriculture. Web. 04 Apr. 2017.&lt;/p&gt;

&lt;p&gt;Högberg, Mona N., et al. “Quantification of Effects of Season and Nitrogen Supply on Tree
Below-Ground Carbon Transfer to Ectomycorrhizal Fungi and Other Soil Organisms in a Boreal Pine Forest.” New Phytologist, vol. 187, no. 2, 15 July 2010, pp. 485-493. EBSCOhost, doi:10.1111/j.1469-8137.2010.03274.x.&lt;/p&gt;

&lt;p&gt;Jelínková, Hana, et al. “Herbivore-Simulated Induction of Defenses in Clonal Networks of
Trembling Aspen (Populus Tremuloides).” Tree Physiology, vol. 32, no. 11, Nov. 2012, pp. 1348-1356. EBSCOhost, search.ebscohost.com/login.aspx?direct=true&amp;amp;db=a9h&amp;amp;AN=83483949.&lt;/p&gt;

&lt;p&gt;Martin, F., et al. “The genome of Laccaria bicolor provides insights into mycorrhizal symbiosis.”
Nature, vol. 452, no. 7183, 2008, p. 88+. General OneFile, &lt;a href=&quot;go.galegroup.com/ps/i.do?p=ITOF&amp;amp;sw=w&amp;amp;u=j220919043&amp;amp;v=2.1&amp;amp;it=r&amp;amp;id=GALE%7CA189654068&amp;amp;asid=07b463289bd8b6cce0e7a45ad784f41e&quot;&gt;go.galegroup.com&lt;/a&gt;. Accessed 30 Mar. 2017.&lt;/p&gt;

&lt;p&gt;Simard, Suzanne W. and David A. Perry. “Net Transfer of Carbon between Ectomycorrhizal Tree
Species in the Field. (Cover Story).” Nature, vol. 388, no. 6642, 07 Aug. 1997, p. 579. EBSCOhost, search.ebscohost.com/login.aspx?direct=true&amp;amp;db=a9h&amp;amp;AN=9708140900.&lt;/p&gt;
</description>
        <pubDate>Mon, 17 Apr 2017 00:00:00 -0500</pubDate>
        <link>http://localhost:4000/communication-between-trees/</link>
        <guid isPermaLink="true">http://localhost:4000/communication-between-trees/</guid>
        
        
        <category>biology</category>
        
        <category>science</category>
        
        <category>essays</category>
        
      </item>
    
      <item>
        <title>Concrete</title>
        <description>&lt;p&gt;A mixture that is both universally noticed and universally ignored.&lt;/p&gt;

&lt;p&gt;When you think of concrete, you may imagine it as something boring and common. However, it is actually fascinating in that such a simple substance could change our world’s infrastructure so greatly. Here I will explain where it came from, how it is made, and how it works.&lt;/p&gt;

&lt;p&gt;It all started in the year 3000 BC. According to Auburn University, that was when Egyptians first began mixing mud with straw to bind dried bricks. Also around this time, the ancient Chinese began using cementitious materials to hold together the bamboo on their boats and to make the Great Wall of China. Concrete was made in Ancient Rome by mixing one part lime, four parts sand, and animal fat, milk or blood. However, sometime around AD 400, the art of concrete was lost with the fall of the Roman Empire. Finally, in 1756, John Smeaton, a British engineer, rediscovered hydraulic cement (mixing cement with water) by repeatedly testing mortar in both fresh and salt water. In 1779, Bry Higgins was issued a patent for hydraulic cement (also known as stucco). In 1824,Joseph Aspdin, bricklayer and mason in Leeds, England, patented what he called Portland cement, since it resembled the stone quarried on the Isle of Portland off the British coast. Little did he know how important the cement would be in the near future. Throughout the rest of the 1800s Portland cement concrete became widely used in poles, beams, ships, buildings, canals, bridges, even skyscrapers… In just 100 years from rediscovery, concrete was already becoming essential to infrastructure. Concrete was becoming more and more popular by the day. Now, we are surrounded by it.&lt;/p&gt;

&lt;p&gt;But how does this amazing mixture get made? According to cement.org, concrete is basically just three things: water, Portland cement, and aggregates (rock and sand). It could also contain admixtures, which are just things added to alter the texture or other properties of the finished concrete. The proportions are roughly 6% air, 11% portland cement, 41% coarse aggregate (think gravel-like), 26% fine aggregate (sand), and 16% water. Any drinkable water can be used for concrete; however, the purer the better. The materials are then mixed together until they are workable. After that all that remains is to put the concrete in the form and cure it by sprinkling water fog. The older the concrete is, the stronger it gets.&lt;/p&gt;

&lt;p&gt;Sure, concrete is useful and we know how it’s made, but how does this all work? According to Northwestern University, the first step is called dissolution, where the cement dissolves, releasing ions into the water. Eventually, the density of the ionic species becomes so great that they will want to become solid. This brings us to the next step, precipitation, where the water-cement mixture forms a new solid substance. This substance coats and sticks to the aggregates to form concrete.&lt;/p&gt;

&lt;p&gt;As you can see, concrete is a very interesting substance that has greatly affected the world in many positive ways.&lt;/p&gt;
</description>
        <pubDate>Wed, 25 Feb 2015 00:00:00 -0600</pubDate>
        <link>http://localhost:4000/concrete/</link>
        <guid isPermaLink="true">http://localhost:4000/concrete/</guid>
        
        
        <category>concrete</category>
        
        <category>science</category>
        
        <category>essays</category>
        
      </item>
    
  </channel>
</rss>
